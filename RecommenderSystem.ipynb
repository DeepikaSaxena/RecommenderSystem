{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender Systems, they are simple algorithms which aim to provide the most relevant and accurate items to the user by filtering useful stuff from of a huge pool of information base. Recommendation engines discovers data patterns in the data set by learning consumers choices and produces the outcomes that co-relates to their needs and interests. Companies nowadays are building smart and intelligent recommendation engines by studying the past behavior of their users. Hence providing them recommendations and choices of their interest in terms of “Relevant Job postings”, “Movies of Interest”, “Suggested Videos”, “Facebook friends that you may know” and “People who bought this also bought this. In this assignment, we are building Item and user Based Recommender System.\n",
    "\n",
    "Item Based Recommender System : These types of recommender system identify similar items based on users’ previous ratings.\n",
    "\n",
    "User Based Recommender System : In this type of recommender system the products are recommended to a user based on the fact that the products have been liked by users similar to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment I am using Movielens Dataset. Dataset can be downloaded from [MovieLens dataset of 100k records](http://files.grouplens.org/datasets/movielens/ml-100k/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is my first approach to build the recommender system: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine, correlation\n",
    "\n",
    "# Loading movielens data\n",
    "# User's data\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('C:/Users/Deepika Saxena/PycharmProjects/ml-100k/u.user', sep='|', names=users_cols,\n",
    "                    parse_dates=True)\n",
    "# Ratings\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('C:/Users/Deepika Saxena/PycharmProjects/ml-100k/u.data', sep='\\t', names=rating_cols)\n",
    "# Movies\n",
    "movie_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies = pd.read_csv('C:/Users/Deepika Saxena/PycharmProjects/ml-100k/u.item', sep='|', names=movie_cols,\n",
    "                     usecols=range(5), encoding='latin-1')\n",
    "\n",
    "# Merging movie data with their ratings\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "# merging movie_ratings data with the User's dataframe\n",
    "df = pd.merge(movie_ratings, users)\n",
    "\n",
    "# pre-processing\n",
    "# dropping colums that aren't needed\n",
    "df.drop(df.columns[[3, 4, 7]], axis=1, inplace=True)\n",
    "ratings.drop(\"unix_timestamp\", inplace=True, axis=1)\n",
    "movies.drop(movies.columns[[3, 4]], inplace=True, axis=1)\n",
    "\n",
    "# Pivot Table(This creates a matrix of users and movie_ratings)\n",
    "ratings_matrix = ratings.pivot_table(index=['movie_id'], columns=['user_id'], values='rating').reset_index(drop=True)\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# specify the range of the reviews\n",
    "lower_rating = ratings['rating'].min()\n",
    "upper_rating = ratings['rating'].max()\n",
    "print('Review Range : {0} to {1}'.format(lower_rating, upper_rating))\n",
    "\n",
    "\n",
    "# Cosine Similarity(Creates a cosine matrix of similaraties ..... which is the pairwise distances\n",
    "# between two items )\n",
    "movie_similarity = 1 - pairwise_distances(ratings_matrix.values, metric=\"cosine\")\n",
    "np.fill_diagonal(movie_similarity, 0)\n",
    "print(movie_similarity)\n",
    "ratings_matrix = pd.DataFrame(movie_similarity)\n",
    "\n",
    "# Recommender\n",
    "try:\n",
    "    # user_inp=input('Enter the reference movie title based on which recommendations are to be made: ')\n",
    "    user_inp = \"Speed (1994)\"\n",
    "    inp = movies[movies['title'] == user_inp].index.tolist()\n",
    "    print(inp)\n",
    "    inp = inp[0]\n",
    "    movies['similarity'] = ratings_matrix.iloc[inp]\n",
    "    movies.columns = ['movie_id', 'title', 'release_date', 'similarity']\n",
    "    movies.head(5)\n",
    "\n",
    "\n",
    "except:\n",
    "    print(\"Sorry, the movie is not in the database!\")\n",
    "\n",
    "print(\"Recommended movies based on your choice of \", user_inp, \": \\n\",\n",
    "      movies.sort_values([\"similarity\"], ascending=False)[1:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I wasn't able to evaluate predictions through the above code. Therefore, I tried a different approach, as follows : *\n",
    "In this approach I used surprise library. It was used to create the dataset and calculate predictions and their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4533868932f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                         unicode_literals)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNNWithMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Movielens-100k dataset\n",
    "# UserID::MovieID::Rating::Timestamp\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "training_set, test_set = train_test_split(data, test_size=.15)\n",
    "\n",
    "# Using user_based T/F to toggle between user-based or item-based collaborative filtering\n",
    "# this is for user based recommender system\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "algo.fit(training_set)\n",
    "\n",
    "# we can now query for specific predicions\n",
    "uid = str(196)  # raw user id\n",
    "iid = str(302)  # raw item id\n",
    "\n",
    "# evaluates prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
    "\n",
    "# run the trained model against the test_set\n",
    "test_pred = algo.test(test_set)\n",
    "\n",
    "# get root mean squared error (RMSE)\n",
    "print(\"User-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)\n",
    "\n",
    "# if you wanted to evaluate on the training_set\n",
    "print(\"User-based Model : Training Set\")\n",
    "train_pred = algo.test(training_set.build_test_set())\n",
    "accuracy.rmse(train_pred)\n",
    "\n",
    "# Calculating for the item based recommender system\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "algo.fit(training_set)\n",
    "\n",
    "# run the trained model against the testset\n",
    "test_pred = algo.test(test_set)\n",
    "\n",
    "# get RMSE\n",
    "print(\"Item-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)\n",
    "\n",
    "# if you wanted to evaluate on the trainset\n",
    "print(\"Item-based Model : Training Set\")\n",
    "train_pred = algo.test(training_set.build_test_set())\n",
    "accuracy.rmse(train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
